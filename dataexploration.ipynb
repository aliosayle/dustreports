{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f3799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connection parameters\n",
    "DATA_SOURCE = \"100.200.2.1\"\n",
    "DATABASE_PATH = r\"D:\\dolly2008\\fer2015.dol\"\n",
    "USERNAME = \"ALIOSS\"\n",
    "PASSWORD = \"$9-j[+Mo$AA833C4FA$\"\n",
    "CLIENT_LIBRARY = r\"C:\\Users\\User\\Downloads\\Compressed\\ibclient64-14.1_x86-64\\ibclient64-14.1.dll\"\n",
    "\n",
    "connection_string = (\n",
    "    f\"DRIVER=Devart ODBC Driver for InterBase;\"\n",
    "    f\"Data Source={DATA_SOURCE};\"\n",
    "    f\"Database={DATABASE_PATH};\"\n",
    "    f\"User ID={USERNAME};\"\n",
    "    f\"Password={PASSWORD};\"\n",
    "    f\"Client Library={CLIENT_LIBRARY};\"\n",
    ")\n",
    "\n",
    "def connect_and_load_table(table_name):\n",
    "    try:\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "        conn.close()\n",
    "        print(f\"✅ {table_name}: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {table_name}: Failed to load\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ Connection setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e62f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database tables...\n",
      "❌ ALLSTOCK: Failed to load\n",
      "❌ DETDESCR: Failed to load\n",
      "❌ INVOICE: Failed to load\n",
      "❌ ITEMS: Failed to load\n",
      "❌ PAYM: Failed to load\n",
      "❌ SACCOUNT: Failed to load\n",
      "❌ STOCK: Failed to load\n",
      "❌ ALLITEM: Failed to load\n",
      "\n",
      "✅ Successfully loaded 0 tables:\n"
     ]
    }
   ],
   "source": [
    "# Load tables with descriptive names\n",
    "print(\"Loading database tables...\")\n",
    "\n",
    "sites_df = connect_and_load_table('ALLSTOCK')          # Site/Location master data\n",
    "categories_df = connect_and_load_table('DETDESCR')     # Category definitions  \n",
    "invoice_headers_df = connect_and_load_table('INVOICE') # Invoice headers\n",
    "sales_details_df = connect_and_load_table('ITEMS')     # Sales transaction details\n",
    "vouchers_df = connect_and_load_table('PAYM')           # Payment vouchers\n",
    "accounts_df = connect_and_load_table('SACCOUNT')       # Statement of accounts\n",
    "inventory_items_df = connect_and_load_table('STOCK')   # Items/Products master\n",
    "inventory_transactions_df = connect_and_load_table('ALLITEM') # All inventory transactions\n",
    "\n",
    "# Create dataframes dictionary with descriptive names\n",
    "dataframes = {\n",
    "    'sites': sites_df,\n",
    "    'categories': categories_df, \n",
    "    'invoice_headers': invoice_headers_df,\n",
    "    'sales_details': sales_details_df,\n",
    "    'vouchers': vouchers_df,\n",
    "    'accounts': accounts_df,\n",
    "    'inventory_items': inventory_items_df,\n",
    "    'inventory_transactions': inventory_transactions_df\n",
    "}\n",
    "\n",
    "# Remove None values and show summary\n",
    "dataframes = {k: v for k, v in dataframes.items() if v is not None}\n",
    "print(f\"\\n✅ Successfully loaded {len(dataframes)} tables:\")\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"  {name}: {df.shape[0]:,} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfeba33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enhanced stock and sales calculation functions ready!\n",
      "\n",
      "Usage examples:\n",
      "• calculate_stock_and_sales('ITEM001', 'SITE001') - Stock and all-time sales for specific item/site\n",
      "• calculate_stock_and_sales('ITEM001', from_date='2025-01-01', to_date='2025-06-20') - Item sales in date range\n",
      "• calculate_stock_and_sales(site_code='SITE001', from_date='2025-05-01') - All items at site from May\n",
      "• calculate_stock_and_sales(from_date='2025-01-01', to_date='2025-03-31') - Q1 sales for all items/sites\n",
      "• get_stock_and_sales_summary('ITEM001') - Quick overview with top 10 results\n",
      "\n",
      "Date format: 'YYYY-MM-DD' (e.g., '2025-06-20')\n"
     ]
    }
   ],
   "source": [
    "# Stock Calculation Functions\n",
    "\n",
    "def calculate_stock_and_sales(item_code=None, site_code=None, from_date=None, to_date=None, show_details=False):\n",
    "    \"\"\"\n",
    "    Calculate current stock and sales for an item at a specific site or across all sites\n",
    "    \n",
    "    Parameters:\n",
    "    - item_code: Item code (if None, calculates for all items)\n",
    "    - site_code: Site code (if None, calculates across all sites)\n",
    "    - from_date: Start date for sales calculation (format: 'YYYY-MM-DD')\n",
    "    - to_date: End date for sales calculation (format: 'YYYY-MM-DD')\n",
    "    - show_details: If True, shows detailed breakdown\n",
    "    \n",
    "    Returns: DataFrame with stock and sales calculations\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Start with inventory transactions for stock calculation\n",
    "    df_stock = inventory_transactions_df.copy()\n",
    "    \n",
    "    # Filter by item if specified\n",
    "    if item_code:\n",
    "        df_stock = df_stock[df_stock['ITEM'] == item_code]\n",
    "        if df_stock.empty:\n",
    "            print(f\"❌ No stock transactions found for item: {item_code}\")\n",
    "            return None\n",
    "    \n",
    "    # Filter by site if specified  \n",
    "    if site_code:\n",
    "        df_stock = df_stock[df_stock['SITE'] == site_code]\n",
    "        if df_stock.empty:\n",
    "            print(f\"❌ No stock transactions found for site: {site_code}\")\n",
    "            return None\n",
    "    \n",
    "    # Fill NaN values with 0 for calculations\n",
    "    df_stock['DEBITQTY'] = df_stock['DEBITQTY'].fillna(0)\n",
    "    df_stock['CREDITQTY'] = df_stock['CREDITQTY'].fillna(0)\n",
    "    \n",
    "    # Calculate stock by grouping\n",
    "    if item_code and site_code:\n",
    "        # Single item, single site\n",
    "        result_df = pd.DataFrame({\n",
    "            'SITE': [site_code],\n",
    "            'ITEM': [item_code],\n",
    "            'TOTAL_IN': [df_stock['DEBITQTY'].sum()],\n",
    "            'TOTAL_OUT': [df_stock['CREDITQTY'].sum()],\n",
    "            'CURRENT_STOCK': [df_stock['DEBITQTY'].sum() - df_stock['CREDITQTY'].sum()],\n",
    "            'STOCK_TRANSACTIONS': [len(df_stock)]\n",
    "        })\n",
    "    elif item_code:\n",
    "        # Single item, all sites\n",
    "        result_df = df_stock.groupby('SITE').agg({\n",
    "            'DEBITQTY': 'sum',\n",
    "            'CREDITQTY': 'sum',\n",
    "            'ITEM': 'first'\n",
    "        }).reset_index()\n",
    "        result_df['CURRENT_STOCK'] = result_df['DEBITQTY'] - result_df['CREDITQTY']\n",
    "        result_df['STOCK_TRANSACTIONS'] = df_stock.groupby('SITE').size().values\n",
    "        result_df = result_df.rename(columns={'DEBITQTY': 'TOTAL_IN', 'CREDITQTY': 'TOTAL_OUT'})\n",
    "        result_df = result_df[['SITE', 'ITEM', 'TOTAL_IN', 'TOTAL_OUT', 'CURRENT_STOCK', 'STOCK_TRANSACTIONS']]\n",
    "    elif site_code:\n",
    "        # All items, single site\n",
    "        result_df = df_stock.groupby('ITEM').agg({\n",
    "            'DEBITQTY': 'sum',\n",
    "            'CREDITQTY': 'sum',\n",
    "            'SITE': 'first'\n",
    "        }).reset_index()\n",
    "        result_df['CURRENT_STOCK'] = result_df['DEBITQTY'] - result_df['CREDITQTY']\n",
    "        result_df['STOCK_TRANSACTIONS'] = df_stock.groupby('ITEM').size().values\n",
    "        result_df = result_df.rename(columns={'DEBITQTY': 'TOTAL_IN', 'CREDITQTY': 'TOTAL_OUT'})\n",
    "        result_df = result_df[['SITE', 'ITEM', 'TOTAL_IN', 'TOTAL_OUT', 'CURRENT_STOCK', 'STOCK_TRANSACTIONS']]\n",
    "    else:\n",
    "        # All items, all sites\n",
    "        result_df = df_stock.groupby(['SITE', 'ITEM']).agg({\n",
    "            'DEBITQTY': 'sum',\n",
    "            'CREDITQTY': 'sum'\n",
    "        }).reset_index()\n",
    "        result_df['CURRENT_STOCK'] = result_df['DEBITQTY'] - result_df['CREDITQTY']\n",
    "        result_df['STOCK_TRANSACTIONS'] = df_stock.groupby(['SITE', 'ITEM']).size().values\n",
    "        result_df = result_df.rename(columns={'DEBITQTY': 'TOTAL_IN', 'CREDITQTY': 'TOTAL_OUT'})\n",
    "    \n",
    "    # Calculate sales analytics from sales_details_df (ITEMS table)\n",
    "    if 'sales_details' in dataframes and sales_details_df is not None:\n",
    "        df_sales = sales_details_df.copy()\n",
    "        \n",
    "        # Filter sales by item and site\n",
    "        if item_code:\n",
    "            df_sales = df_sales[df_sales['ITEM'] == item_code]\n",
    "        if site_code:\n",
    "            df_sales = df_sales[df_sales['SITE'] == site_code]\n",
    "        \n",
    "        # Convert FDATE to datetime if it's not already\n",
    "        if 'FDATE' in df_sales.columns:\n",
    "            df_sales['FDATE'] = pd.to_datetime(df_sales['FDATE'], errors='coerce')\n",
    "            \n",
    "            # Filter by date range if specified\n",
    "            if from_date:\n",
    "                from_date_dt = pd.to_datetime(from_date)\n",
    "                df_sales = df_sales[df_sales['FDATE'] >= from_date_dt]\n",
    "            if to_date:\n",
    "                to_date_dt = pd.to_datetime(to_date)\n",
    "                df_sales = df_sales[df_sales['FDATE'] <= to_date_dt]\n",
    "        \n",
    "        # Filter for sales transactions (FTYPE = 1 for sales, FTYPE = 2 for returns)\n",
    "        if 'FTYPE' in df_sales.columns:\n",
    "            sales_only = df_sales[df_sales['FTYPE'].isin([1, 2])]\n",
    "        else:\n",
    "            sales_only = df_sales\n",
    "        \n",
    "        # Fill NaN values\n",
    "        sales_only['QTY'] = sales_only['QTY'].fillna(0)\n",
    "        \n",
    "        # Calculate daily sales analytics\n",
    "        def calculate_sales_analytics(group, from_date_param=None, to_date_param=None):\n",
    "            if group.empty or 'FDATE' not in group.columns:\n",
    "                return pd.Series({\n",
    "                    'MAX_DAILY_SALES': 0,\n",
    "                    'MIN_DAILY_SALES': 0, \n",
    "                    'AVG_DAILY_SALES': 0,\n",
    "                    'SALES_TRANSACTIONS': 0,\n",
    "                    'TOTAL_SALES_QTY': 0,\n",
    "                    'SALES_PERIOD_DAYS': 0\n",
    "                })\n",
    "            \n",
    "            # Group by date and sum quantities\n",
    "            daily_sales = group.groupby('FDATE')['QTY'].sum()\n",
    "            \n",
    "            # Calculate period metrics\n",
    "            total_sales_qty = group['QTY'].sum()\n",
    "            \n",
    "            # Use specified date range if provided, otherwise use actual sales date range\n",
    "            if from_date_param and to_date_param:\n",
    "                from_dt = pd.to_datetime(from_date_param)\n",
    "                to_dt = pd.to_datetime(to_date_param)\n",
    "                period_days = (to_dt - from_dt).days + 1\n",
    "            elif from_date_param:\n",
    "                from_dt = pd.to_datetime(from_date_param)\n",
    "                max_date = group['FDATE'].max()\n",
    "                period_days = (max_date - from_dt).days + 1\n",
    "            elif to_date_param:\n",
    "                min_date = group['FDATE'].min()\n",
    "                to_dt = pd.to_datetime(to_date_param)\n",
    "                period_days = (to_dt - min_date).days + 1\n",
    "            else:\n",
    "                # No date range specified, use actual sales period\n",
    "                min_date = group['FDATE'].min()\n",
    "                max_date = group['FDATE'].max()\n",
    "                period_days = (max_date - min_date).days + 1 if min_date != max_date else 1\n",
    "            \n",
    "            # Exclude zero sales days for min calculation\n",
    "            non_zero_sales = daily_sales[daily_sales > 0]\n",
    "            \n",
    "            max_sales = daily_sales.max() if not daily_sales.empty else 0\n",
    "            min_sales = non_zero_sales.min() if not non_zero_sales.empty else 0\n",
    "            \n",
    "            # Calculate average daily sales using the full specified period\n",
    "            avg_sales = total_sales_qty / period_days if period_days > 0 else 0\n",
    "            \n",
    "            total_transactions = len(group)\n",
    "            \n",
    "            return pd.Series({\n",
    "                'MAX_DAILY_SALES': max_sales,\n",
    "                'MIN_DAILY_SALES': min_sales,\n",
    "                'AVG_DAILY_SALES': avg_sales,\n",
    "                'SALES_TRANSACTIONS': total_transactions,\n",
    "                'TOTAL_SALES_QTY': total_sales_qty,\n",
    "                'SALES_PERIOD_DAYS': period_days\n",
    "            })\n",
    "        \n",
    "        # Calculate analytics by same grouping as stock\n",
    "        if item_code and site_code:\n",
    "            # Single item, single site\n",
    "            analytics = calculate_sales_analytics(sales_only, from_date, to_date)\n",
    "            sales_analytics = pd.DataFrame({\n",
    "                'SITE': [site_code],\n",
    "                'ITEM': [item_code],\n",
    "                'MAX_DAILY_SALES': [analytics['MAX_DAILY_SALES']],\n",
    "                'MIN_DAILY_SALES': [analytics['MIN_DAILY_SALES']], \n",
    "                'AVG_DAILY_SALES': [analytics['AVG_DAILY_SALES']],\n",
    "                'SALES_TRANSACTIONS': [analytics['SALES_TRANSACTIONS']],\n",
    "                'TOTAL_SALES_QTY': [analytics['TOTAL_SALES_QTY']],\n",
    "                'SALES_PERIOD_DAYS': [analytics['SALES_PERIOD_DAYS']]\n",
    "            })\n",
    "        elif item_code:\n",
    "            # Single item, all sites\n",
    "            sales_analytics = sales_only.groupby('SITE').apply(lambda x: calculate_sales_analytics(x, from_date, to_date)).reset_index()\n",
    "            sales_analytics['ITEM'] = item_code\n",
    "        elif site_code:\n",
    "            # All items, single site\n",
    "            sales_analytics = sales_only.groupby('ITEM').apply(lambda x: calculate_sales_analytics(x, from_date, to_date)).reset_index()\n",
    "            sales_analytics['SITE'] = site_code\n",
    "        else:\n",
    "            # All items, all sites\n",
    "            sales_analytics = sales_only.groupby(['SITE', 'ITEM']).apply(lambda x: calculate_sales_analytics(x, from_date, to_date)).reset_index()\n",
    "        \n",
    "        # Merge stock and sales analytics\n",
    "        result_df = result_df.merge(sales_analytics[['SITE', 'ITEM', 'MAX_DAILY_SALES', 'MIN_DAILY_SALES', 'AVG_DAILY_SALES', 'SALES_TRANSACTIONS', 'TOTAL_SALES_QTY', 'SALES_PERIOD_DAYS']], \n",
    "                                   on=['SITE', 'ITEM'], how='left')\n",
    "        result_df['MAX_DAILY_SALES'] = result_df['MAX_DAILY_SALES'].fillna(0)\n",
    "        result_df['MIN_DAILY_SALES'] = result_df['MIN_DAILY_SALES'].fillna(0)\n",
    "        result_df['AVG_DAILY_SALES'] = result_df['AVG_DAILY_SALES'].fillna(0)\n",
    "        result_df['SALES_TRANSACTIONS'] = result_df['SALES_TRANSACTIONS'].fillna(0)\n",
    "        result_df['TOTAL_SALES_QTY'] = result_df['TOTAL_SALES_QTY'].fillna(0)\n",
    "        result_df['SALES_PERIOD_DAYS'] = result_df['SALES_PERIOD_DAYS'].fillna(0)\n",
    "    else:\n",
    "        # Add empty sales columns if sales data not available\n",
    "        result_df['MAX_DAILY_SALES'] = 0\n",
    "        result_df['MIN_DAILY_SALES'] = 0\n",
    "        result_df['AVG_DAILY_SALES'] = 0\n",
    "        result_df['SALES_TRANSACTIONS'] = 0\n",
    "        result_df['TOTAL_SALES_QTY'] = 0\n",
    "        result_df['SALES_PERIOD_DAYS'] = 0\n",
    "    \n",
    "    # Calculate stock autonomy (days of stock remaining at current sales rate)\n",
    "    result_df['STOCK_AUTONOMY_DAYS'] = result_df.apply(\n",
    "        lambda row: (row['CURRENT_STOCK'] / row['AVG_DAILY_SALES']) \n",
    "        if row['AVG_DAILY_SALES'] > 0 else float('inf'), axis=1\n",
    "    )\n",
    "    # Cap infinity values at 9999 for display purposes\n",
    "    result_df['STOCK_AUTONOMY_DAYS'] = result_df['STOCK_AUTONOMY_DAYS'].replace(float('inf'), 9999)\n",
    "    \n",
    "    # Add site names if available\n",
    "    if 'sites' in dataframes and sites_df is not None:\n",
    "        site_names = sites_df[['ID', 'SITE']].drop_duplicates()\n",
    "        site_names = site_names.rename(columns={'ID': 'SITE', 'SITE': 'SITE_NAME'})\n",
    "        result_df = result_df.merge(site_names, on='SITE', how='left')\n",
    "    \n",
    "    # Add item names if available\n",
    "    if 'inventory_items' in dataframes and inventory_items_df is not None:\n",
    "        # Use DESCR1 as primary item name (item description)\n",
    "        item_names = inventory_items_df[['ITEM', 'DESCR1']].drop_duplicates()\n",
    "        item_names['ITEM_NAME'] = item_names['DESCR1'].fillna('').astype(str)\n",
    "        \n",
    "        # Merge with result_df\n",
    "        result_df = result_df.merge(\n",
    "            item_names[['ITEM', 'ITEM_NAME']], \n",
    "            on='ITEM', how='left'\n",
    "        )\n",
    "    else:\n",
    "        # If no item data available, create empty column\n",
    "        result_df['ITEM_NAME'] = None\n",
    "    \n",
    "    # Reorder columns to show: Site, Item, Item Description, Current Stock, Total Sales, Avg Sales/Day, Max/Min Daily, Stock Autonomy, Transactions\n",
    "    final_cols = ['SITE', 'ITEM', 'ITEM_NAME', 'CURRENT_STOCK', 'TOTAL_SALES_QTY', 'AVG_DAILY_SALES', 'MAX_DAILY_SALES', 'MIN_DAILY_SALES', 'STOCK_AUTONOMY_DAYS', 'SALES_TRANSACTIONS']\n",
    "    \n",
    "    # Keep only the columns we want in the final output\n",
    "    available_cols = [col for col in final_cols if col in result_df.columns]\n",
    "    result_df = result_df[available_cols]\n",
    "    \n",
    "    # Sort by current stock descending\n",
    "    result_df = result_df.sort_values('CURRENT_STOCK', ascending=False)\n",
    "    \n",
    "    if show_details:\n",
    "        date_range_str = \"\"\n",
    "        if from_date or to_date:\n",
    "            date_range_str = f\" (Sales from {from_date or 'start'} to {to_date or 'end'})\"\n",
    "        \n",
    "        print(f\"\\n📊 Stock & Sales Analytics{date_range_str}:\")\n",
    "        print(f\"Items analyzed: {result_df['ITEM'].nunique():,}\")\n",
    "        print(f\"Sites analyzed: {result_df['SITE'].nunique():,}\")\n",
    "        print(f\"Total current stock: {result_df['CURRENT_STOCK'].sum():,.0f}\")\n",
    "        print(f\"Average stock autonomy: {result_df[result_df['STOCK_AUTONOMY_DAYS'] < 9999]['STOCK_AUTONOMY_DAYS'].mean():.1f} days\")\n",
    "        print(f\"Items with positive stock: {(result_df['CURRENT_STOCK'] > 0).sum():,}\")\n",
    "        print(f\"Items with sales activity: {(result_df['MAX_DAILY_SALES'] > 0).sum():,}\")\n",
    "        print(f\"Items with low stock (< 30 days): {(result_df['STOCK_AUTONOMY_DAYS'] < 30).sum():,}\")\n",
    "        print(f\"Total sales transactions: {result_df['SALES_TRANSACTIONS'].sum():,.0f}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def get_stock_and_sales_summary(item_code=None, site_code=None, from_date=None, to_date=None):\n",
    "    \"\"\"Quick stock and sales summary with top results\"\"\"\n",
    "    result = calculate_stock_and_sales(item_code, site_code, from_date, to_date, show_details=True)\n",
    "    if result is not None and not result.empty:\n",
    "        print(f\"\\n📋 Top 10 Results:\")\n",
    "        display(result.head(10))\n",
    "    return result\n",
    "\n",
    "# Keep backward compatibility\n",
    "def calculate_stock(item_code=None, site_code=None, show_details=False):\n",
    "    \"\"\"Legacy function - use calculate_stock_and_sales for full functionality\"\"\"\n",
    "    return calculate_stock_and_sales(item_code, site_code, show_details=show_details)\n",
    "\n",
    "print(\"✅ Enhanced stock and sales calculation functions ready!\")\n",
    "print(\"\\nUsage examples:\")\n",
    "print(\"• calculate_stock_and_sales('ITEM001', 'SITE001') - Stock and all-time sales for specific item/site\")\n",
    "print(\"• calculate_stock_and_sales('ITEM001', from_date='2025-01-01', to_date='2025-06-20') - Item sales in date range\")\n",
    "print(\"• calculate_stock_and_sales(site_code='SITE001', from_date='2025-05-01') - All items at site from May\")\n",
    "print(\"• calculate_stock_and_sales(from_date='2025-01-01', to_date='2025-03-31') - Q1 sales for all items/sites\")\n",
    "print(\"• get_stock_and_sales_summary('ITEM001') - Quick overview with top 10 results\")\n",
    "print(\"\\nDate format: 'YYYY-MM-DD' (e.g., '2025-06-20')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfd48db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcalculate_stock_and_sales\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mF001\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m14L\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025-06-01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025-06-15\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mcalculate_stock_and_sales\u001b[39m\u001b[34m(item_code, site_code, from_date, to_date, show_details)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Start with inventory transactions for stock calculation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m df_stock = \u001b[43minventory_transactions_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m()\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Filter by item if specified\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m item_code:\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "calculate_stock_and_sales('F001', '14L', '2025-06-01', '2025-06-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to troubleshoot webapp issue\n",
    "print(\"Testing database connection...\")\n",
    "try:\n",
    "    test_conn = pyodbc.connect(connection_string)\n",
    "    print(\"✅ Connection successful\")\n",
    "    \n",
    "    # Test a simple query\n",
    "    cursor = test_conn.cursor()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM ALLSTOCK\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"✅ ALLSTOCK table has {count} rows\")\n",
    "    \n",
    "    test_conn.close()\n",
    "    print(\"✅ Connection closed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e6410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "Testing groupby apply approach...\n",
      "✅ Standard groupby.apply() works fine\n",
      "Result shape: (57, 2)\n",
      "Result with warnings visible completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5772\\1327024254.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result2 = test_df.groupby('ITEM').apply(lambda x: pd.Series({'count': len(x), 'sum_qty': x['QTY'].sum()}))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check pandas version and groupby approach\n",
    "import pandas as pd\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "# Test the groupby approach used in the notebook\n",
    "test_df = sales_details_df.head(100).copy()\n",
    "test_df['QTY'] = test_df['QTY'].fillna(0)\n",
    "\n",
    "print(\"Testing groupby apply approach...\")\n",
    "try:\n",
    "    # This is the exact approach from the notebook\n",
    "    result = test_df.groupby('ITEM').apply(lambda x: pd.Series({'count': len(x), 'sum_qty': x['QTY'].sum()}))\n",
    "    print(\"✅ Standard groupby.apply() works fine\")\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error with groupby.apply(): {e}\")\n",
    "\n",
    "# Test with warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('default')  # Show warnings\n",
    "result2 = test_df.groupby('ITEM').apply(lambda x: pd.Series({'count': len(x), 'sum_qty': x['QTY'].sum()}))\n",
    "print(\"Result with warnings visible completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
