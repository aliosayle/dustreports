{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f3799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connection setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connection parameters\n",
    "DATA_SOURCE = \"100.200.2.1\"\n",
    "DATABASE_PATH = r\"D:\\dolly2008\\fer2015.dol\"\n",
    "USERNAME = \"ALIOSS\"\n",
    "PASSWORD = \"$9-j[+Mo$AA833C4FA$\"\n",
    "CLIENT_LIBRARY = r\"C:\\Users\\User\\Downloads\\Compressed\\ibclient64-14.1_x86-64\\ibclient64-14.1.dll\"\n",
    "\n",
    "connection_string = (\n",
    "    f\"DRIVER=Devart ODBC Driver for InterBase;\"\n",
    "    f\"Data Source={DATA_SOURCE};\"\n",
    "    f\"Database={DATABASE_PATH};\"\n",
    "    f\"User ID={USERNAME};\"\n",
    "    f\"Password={PASSWORD};\"\n",
    "    f\"Client Library={CLIENT_LIBRARY};\"\n",
    ")\n",
    "\n",
    "def connect_and_load_table(table_name):\n",
    "    \"\"\"Load a table from the database using manual DataFrame creation\"\"\"\n",
    "    try:\n",
    "        print(f\"üîÑ Connecting to database for table {table_name}...\")\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"‚úÖ Connected successfully, loading {table_name}...\")\n",
    "        \n",
    "        # Execute query and get column names\n",
    "        cursor.execute(f\"SELECT * FROM {table_name}\")\n",
    "        columns = [column[0] for column in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        # Convert to DataFrame manually\n",
    "        df = pd.DataFrame([list(row) for row in rows], columns=columns)\n",
    "        \n",
    "        conn.close()\n",
    "        print(f\"‚úÖ {table_name}: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {table_name}: Failed to load - {e}\")\n",
    "        print(f\"   Connection string: {connection_string[:50]}...\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Connection setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e62f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading database tables...\n",
      "üîÑ Connecting to database for table ALLSTOCK...\n",
      "‚úÖ Connected successfully, loading ALLSTOCK...\n",
      "‚úÖ ALLSTOCK: 155 rows √ó 18 columns\n",
      "üîÑ Connecting to database for table DETDESCR...\n",
      "‚úÖ Connected successfully, loading DETDESCR...\n",
      "‚úÖ DETDESCR: 159 rows √ó 10 columns\n",
      "üîÑ Connecting to database for table INVOICE...\n",
      "‚úÖ Connected successfully, loading INVOICE...\n",
      "‚úÖ INVOICE: 207,949 rows √ó 54 columns\n",
      "üîÑ Connecting to database for table ITEMS...\n",
      "‚úÖ Connected successfully, loading ITEMS...\n",
      "‚úÖ INVOICE: 207,949 rows √ó 54 columns\n",
      "üîÑ Connecting to database for table ITEMS...\n",
      "‚úÖ Connected successfully, loading ITEMS...\n",
      "‚úÖ ITEMS: 2,405,320 rows √ó 54 columns\n",
      "üîÑ Connecting to database for table PAYM...\n",
      "‚úÖ Connected successfully, loading PAYM...\n",
      "‚úÖ ITEMS: 2,405,320 rows √ó 54 columns\n",
      "üîÑ Connecting to database for table PAYM...\n",
      "‚úÖ Connected successfully, loading PAYM...\n",
      "‚úÖ PAYM: 192,430 rows √ó 41 columns\n",
      "üîÑ Connecting to database for table SACCOUNT...\n",
      "‚úÖ Connected successfully, loading SACCOUNT...\n",
      "‚úÖ PAYM: 192,430 rows √ó 41 columns\n",
      "üîÑ Connecting to database for table SACCOUNT...\n",
      "‚úÖ Connected successfully, loading SACCOUNT...\n",
      "‚úÖ SACCOUNT: 749,118 rows √ó 41 columns\n",
      "üîÑ Connecting to database for table STOCK...\n",
      "‚úÖ Connected successfully, loading STOCK...\n",
      "‚úÖ STOCK: 1,128 rows √ó 83 columns\n",
      "üîÑ Connecting to database for table ALLITEM...\n",
      "‚úÖ Connected successfully, loading ALLITEM...\n",
      "‚úÖ SACCOUNT: 749,118 rows √ó 41 columns\n",
      "üîÑ Connecting to database for table STOCK...\n",
      "‚úÖ Connected successfully, loading STOCK...\n",
      "‚úÖ STOCK: 1,128 rows √ó 83 columns\n",
      "üîÑ Connecting to database for table ALLITEM...\n",
      "‚úÖ Connected successfully, loading ALLITEM...\n",
      "‚úÖ ALLITEM: 2,689,439 rows √ó 12 columns\n",
      "\n",
      "‚úÖ Successfully loaded 8 tables:\n",
      "  sites: 155 rows √ó 18 columns\n",
      "  categories: 159 rows √ó 10 columns\n",
      "  invoice_headers: 207,949 rows √ó 54 columns\n",
      "  sales_details: 2,405,320 rows √ó 54 columns\n",
      "  vouchers: 192,430 rows √ó 41 columns\n",
      "  accounts: 749,118 rows √ó 41 columns\n",
      "  inventory_items: 1,128 rows √ó 83 columns\n",
      "  inventory_transactions: 2,689,439 rows √ó 12 columns\n",
      "‚úÖ ALLITEM: 2,689,439 rows √ó 12 columns\n",
      "\n",
      "‚úÖ Successfully loaded 8 tables:\n",
      "  sites: 155 rows √ó 18 columns\n",
      "  categories: 159 rows √ó 10 columns\n",
      "  invoice_headers: 207,949 rows √ó 54 columns\n",
      "  sales_details: 2,405,320 rows √ó 54 columns\n",
      "  vouchers: 192,430 rows √ó 41 columns\n",
      "  accounts: 749,118 rows √ó 41 columns\n",
      "  inventory_items: 1,128 rows √ó 83 columns\n",
      "  inventory_transactions: 2,689,439 rows √ó 12 columns\n"
     ]
    }
   ],
   "source": [
    "# Load tables with descriptive names\n",
    "print(\"Loading database tables...\")\n",
    "\n",
    "sites_df = connect_and_load_table('ALLSTOCK')          # Site/Location master data\n",
    "categories_df = connect_and_load_table('DETDESCR')     # Category definitions  \n",
    "invoice_headers_df = connect_and_load_table('INVOICE') # Invoice headers\n",
    "sales_details_df = connect_and_load_table('ITEMS')     # Sales transaction details\n",
    "vouchers_df = connect_and_load_table('PAYM')           # Payment vouchers\n",
    "accounts_df = connect_and_load_table('SACCOUNT')       # Statement of accounts\n",
    "inventory_items_df = connect_and_load_table('STOCK')   # Items/Products master\n",
    "inventory_transactions_df = connect_and_load_table('ALLITEM') # All inventory transactions\n",
    "\n",
    "# Create dataframes dictionary with descriptive names\n",
    "dataframes = {\n",
    "    'sites': sites_df,\n",
    "    'categories': categories_df, \n",
    "    'invoice_headers': invoice_headers_df,\n",
    "    'sales_details': sales_details_df,\n",
    "    'vouchers': vouchers_df,\n",
    "    'accounts': accounts_df,\n",
    "    'inventory_items': inventory_items_df,\n",
    "    'inventory_transactions': inventory_transactions_df\n",
    "}\n",
    "\n",
    "# Remove None values and show summary\n",
    "dataframes = {k: v for k, v in dataframes.items() if v is not None}\n",
    "print(f\"\\n‚úÖ Successfully loaded {len(dataframes)} tables:\")\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"  {name}: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ffc08dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing database connection...\n",
      "‚úÖ Database connection test successful\n",
      "\n",
      "Testing one table load...\n",
      "üîÑ Connecting to database for table ALLSTOCK...\n",
      "‚úÖ Connected successfully, loading ALLSTOCK...\n",
      "‚úÖ ALLSTOCK: 155 rows √ó 18 columns\n"
     ]
    }
   ],
   "source": [
    "# Test connection first\n",
    "print(\"Testing database connection...\")\n",
    "try:\n",
    "    test_conn = pyodbc.connect(connection_string)\n",
    "    test_conn.close()\n",
    "    print(\"‚úÖ Database connection test successful\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database connection test failed: {e}\")\n",
    "    print(f\"Connection string: {connection_string}\")\n",
    "\n",
    "# Test loading just one table\n",
    "print(\"\\nTesting one table load...\")\n",
    "test_df = connect_and_load_table('ALLSTOCK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b97cd9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing direct pyodbc query...\n",
      "‚úÖ Direct query successful - got 5 rows\n",
      "Columns: ['ID', 'SITE', 'STACTIVE', 'SIDNO', 'SID606', 'MYCHECK', 'TEL', 'MYCHECK2', 'PLACE', 'FREIGHT', 'TARGET', 'PERCENTAGE', 'PERCENTAGE2', 'SID2', 'MYORDER', 'MYNAME', 'PERC', 'JOB']\n",
      "\n",
      "Testing manual DataFrame creation...\n",
      "‚úÖ Manual DataFrame creation successful: 155 rows √ó 18 columns\n",
      "Columns: ['ID', 'SITE', 'STACTIVE', 'SIDNO', 'SID606', 'MYCHECK', 'TEL', 'MYCHECK2', 'PLACE', 'FREIGHT', 'TARGET', 'PERCENTAGE', 'PERCENTAGE2', 'SID2', 'MYORDER', 'MYNAME', 'PERC', 'JOB']\n"
     ]
    }
   ],
   "source": [
    "# Test direct pyodbc approach\n",
    "print(\"Testing direct pyodbc query...\")\n",
    "try:\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM ALLSTOCK\")\n",
    "    rows = cursor.fetchmany(5)  # Just get first 5 rows\n",
    "    print(f\"‚úÖ Direct query successful - got {len(rows)} rows\")\n",
    "    print(f\"Columns: {[column[0] for column in cursor.description]}\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Direct query failed: {e}\")\n",
    "\n",
    "# Test manual DataFrame creation\n",
    "print(\"\\nTesting manual DataFrame creation...\")\n",
    "try:\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM ALLSTOCK\")\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Convert to DataFrame manually\n",
    "    df = pd.DataFrame([list(row) for row in rows], columns=columns)\n",
    "    print(f\"‚úÖ Manual DataFrame creation successful: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Manual DataFrame creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfeba33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced stock and sales calculation functions ready!\n",
      "\n",
      "Usage examples:\n",
      "‚Ä¢ calculate_stock_and_sales('ITEM001', 'SITE001') - Stock and all-time sales for specific item/site\n",
      "‚Ä¢ calculate_stock_and_sales('ITEM001', from_date='2025-01-01', to_date='2025-06-20') - Item sales in date range\n",
      "‚Ä¢ calculate_stock_and_sales(site_code='SITE001', from_date='2025-05-01') - All items at site from May\n",
      "‚Ä¢ calculate_stock_and_sales(from_date='2025-01-01', to_date='2025-03-31') - Q1 sales for all items/sites\n",
      "‚Ä¢ get_stock_and_sales_summary('ITEM001') - Quick overview with top 10 results\n",
      "\n",
      "Date format: 'YYYY-MM-DD' (e.g., '2025-06-20')\n"
     ]
    }
   ],
   "source": [
    "# Stock Calculation Functions\n",
    "\n",
    "def calculate_stock_and_sales(item_code=None, site_code=None, from_date=None, to_date=None, show_details=False):\n",
    "    \"\"\"\n",
    "    Calculate current stock and sales for an item at a specific site or across all sites\n",
    "    \n",
    "    Parameters:\n",
    "    - item_code: Item code (if None, calculates for all items)\n",
    "    - site_code: Site code (if None, calculates across all sites)\n",
    "    - from_date: Start date for sales calculation (format: 'YYYY-MM-DD')\n",
    "    - to_date: End date for sales calculation (format: 'YYYY-MM-DD')\n",
    "    - show_details: If True, shows detailed breakdown\n",
    "    \n",
    "    Returns: DataFrame with stock and sales calculations\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Start with inventory transactions for stock calculation\n",
    "    df_stock = inventory_transactions_df.copy()\n",
    "    \n",
    "    # Filter by item if specified\n",
    "    if item_code:\n",
    "        df_stock = df_stock[df_stock['ITEM'] == item_code]\n",
    "        if df_stock.empty:\n",
    "            print(f\"‚ùå No stock transactions found for item: {item_code}\")\n",
    "            return None\n",
    "    \n",
    "    # Filter by site if specified  \n",
    "    if site_code:\n",
    "        df_stock = df_stock[df_stock['SITE'] == site_code]\n",
    "        if df_stock.empty:\n",
    "            print(f\"‚ùå No stock transactions found for site: {site_code}\")\n",
    "            return None\n",
    "    \n",
    "    # Fill NaN values with 0 for calculations\n",
    "    df_stock['DEBITQTY'] = df_stock['DEBITQTY'].fillna(0)\n",
    "    df_stock['CREDITQTY'] = df_stock['CREDITQTY'].fillna(0)\n",
    "    \n",
    "    # Calculate stock by grouping\n",
    "    if item_code and site_code:\n",
    "        # Single item, single site\n",
    "        result_df = pd.DataFrame({\n",
    "            'SITE': [site_code],\n",
    "            'ITEM': [item_code],\n",
    "            'TOTAL_IN': [df_stock['DEBITQTY'].sum()],\n",
    "            'TOTAL_OUT': [df_stock['CREDITQTY'].sum()],\n",
    "            'CURRENT_STOCK': [df_stock['DEBITQTY'].sum() - df_stock['CREDITQTY'].sum()],\n",
    "            'STOCK_TRANSACTIONS': [len(df_stock)]\n",
    "        })\n",
    "    elif item_code:\n",
    "        # Single item, all sites\n",
    "        result_df = df_stock.groupby('SITE').agg({\n",
    "            'DEBITQTY': 'sum',\n",
    "            'CREDITQTY': 'sum',\n",
    "            'ITEM': 'first'\n",
    "        }).reset_index()\n",
    "        result_df['CURRENT_STOCK'] = result_df['DEBITQTY'] - result_df['CREDITQTY']\n",
    "        result_df['STOCK_TRANSACTIONS'] = df_stock.groupby('SITE').size().values\n",
    "        result_df = result_df.rename(columns={'DEBITQTY': 'TOTAL_IN', 'CREDITQTY': 'TOTAL_OUT'})\n",
    "        result_df = result_df[['SITE', 'ITEM', 'TOTAL_IN', 'TOTAL_OUT', 'CURRENT_STOCK', 'STOCK_TRANSACTIONS']]\n",
    "    elif site_code:\n",
    "        # All items, single site\n",
    "        result_df = df_stock.groupby('ITEM').agg({\n",
    "            'DEBITQTY': 'sum',\n",
    "            'CREDITQTY': 'sum',\n",
    "            'SITE': 'first'\n",
    "        }).reset_index()\n",
    "        result_df['CURRENT_STOCK'] = result_df['DEBITQTY'] - result_df['CREDITQTY']\n",
    "        result_df['STOCK_TRANSACTIONS'] = df_stock.groupby('ITEM').size().values\n",
    "        result_df = result_df.rename(columns={'DEBITQTY': 'TOTAL_IN', 'CREDITQTY': 'TOTAL_OUT'})\n",
    "        result_df = result_df[['SITE', 'ITEM', 'TOTAL_IN', 'TOTAL_OUT', 'CURRENT_STOCK', 'STOCK_TRANSACTIONS']]\n",
    "    else:\n",
    "        # All items, all sites\n",
    "        result_df = df_stock.groupby(['SITE', 'ITEM']).agg({\n",
    "            'DEBITQTY': 'sum',\n",
    "            'CREDITQTY': 'sum'\n",
    "        }).reset_index()\n",
    "        result_df['CURRENT_STOCK'] = result_df['DEBITQTY'] - result_df['CREDITQTY']\n",
    "        result_df['STOCK_TRANSACTIONS'] = df_stock.groupby(['SITE', 'ITEM']).size().values\n",
    "        result_df = result_df.rename(columns={'DEBITQTY': 'TOTAL_IN', 'CREDITQTY': 'TOTAL_OUT'})\n",
    "    \n",
    "    # Calculate sales analytics from sales_details_df (ITEMS table)\n",
    "    if 'sales_details' in dataframes and sales_details_df is not None:\n",
    "        df_sales = sales_details_df.copy()\n",
    "        \n",
    "        # Filter sales by item and site\n",
    "        if item_code:\n",
    "            df_sales = df_sales[df_sales['ITEM'] == item_code]\n",
    "        if site_code:\n",
    "            df_sales = df_sales[df_sales['SITE'] == site_code]\n",
    "        \n",
    "        # Convert FDATE to datetime if it's not already\n",
    "        if 'FDATE' in df_sales.columns:\n",
    "            df_sales['FDATE'] = pd.to_datetime(df_sales['FDATE'], errors='coerce')\n",
    "            \n",
    "            # Filter by date range if specified\n",
    "            if from_date:\n",
    "                from_date_dt = pd.to_datetime(from_date)\n",
    "                df_sales = df_sales[df_sales['FDATE'] >= from_date_dt]\n",
    "            if to_date:\n",
    "                to_date_dt = pd.to_datetime(to_date)\n",
    "                df_sales = df_sales[df_sales['FDATE'] <= to_date_dt]\n",
    "        \n",
    "        # Filter for sales transactions (FTYPE = 1 for sales, FTYPE = 2 for returns)\n",
    "        if 'FTYPE' in df_sales.columns:\n",
    "            sales_only = df_sales[df_sales['FTYPE'].isin([1, 2])]\n",
    "        else:\n",
    "            sales_only = df_sales\n",
    "        \n",
    "        # Fill NaN values\n",
    "        sales_only['QTY'] = sales_only['QTY'].fillna(0)\n",
    "        \n",
    "        # Calculate daily sales analytics\n",
    "        def calculate_sales_analytics(group, from_date_param=None, to_date_param=None):\n",
    "            if group.empty or 'FDATE' not in group.columns:\n",
    "                return pd.Series({\n",
    "                    'MAX_DAILY_SALES': 0,\n",
    "                    'MIN_DAILY_SALES': 0, \n",
    "                    'AVG_DAILY_SALES': 0,\n",
    "                    'SALES_TRANSACTIONS': 0,\n",
    "                    'TOTAL_SALES_QTY': 0,\n",
    "                    'SALES_PERIOD_DAYS': 0\n",
    "                })\n",
    "            \n",
    "            # Group by date and sum quantities\n",
    "            daily_sales = group.groupby('FDATE')['QTY'].sum()\n",
    "            \n",
    "            # Calculate period metrics\n",
    "            total_sales_qty = group['QTY'].sum()\n",
    "            \n",
    "            # Use specified date range if provided, otherwise use actual sales date range\n",
    "            if from_date_param and to_date_param:\n",
    "                from_dt = pd.to_datetime(from_date_param)\n",
    "                to_dt = pd.to_datetime(to_date_param)\n",
    "                period_days = (to_dt - from_dt).days + 1\n",
    "            elif from_date_param:\n",
    "                from_dt = pd.to_datetime(from_date_param)\n",
    "                max_date = group['FDATE'].max()\n",
    "                period_days = (max_date - from_dt).days + 1\n",
    "            elif to_date_param:\n",
    "                min_date = group['FDATE'].min()\n",
    "                to_dt = pd.to_datetime(to_date_param)\n",
    "                period_days = (to_dt - min_date).days + 1\n",
    "            else:\n",
    "                # No date range specified, use actual sales period\n",
    "                min_date = group['FDATE'].min()\n",
    "                max_date = group['FDATE'].max()\n",
    "                period_days = (max_date - min_date).days + 1 if min_date != max_date else 1\n",
    "            \n",
    "            # Exclude zero sales days for min calculation\n",
    "            non_zero_sales = daily_sales[daily_sales > 0]\n",
    "            \n",
    "            max_sales = daily_sales.max() if not daily_sales.empty else 0\n",
    "            min_sales = non_zero_sales.min() if not non_zero_sales.empty else 0\n",
    "            \n",
    "            # Calculate average daily sales using the full specified period\n",
    "            avg_sales = total_sales_qty / period_days if period_days > 0 else 0\n",
    "            \n",
    "            total_transactions = len(group)\n",
    "            \n",
    "            return pd.Series({\n",
    "                'MAX_DAILY_SALES': max_sales,\n",
    "                'MIN_DAILY_SALES': min_sales,\n",
    "                'AVG_DAILY_SALES': avg_sales,\n",
    "                'SALES_TRANSACTIONS': total_transactions,\n",
    "                'TOTAL_SALES_QTY': total_sales_qty,\n",
    "                'SALES_PERIOD_DAYS': period_days\n",
    "            })\n",
    "        \n",
    "        # Calculate analytics by same grouping as stock\n",
    "        if item_code and site_code:\n",
    "            # Single item, single site\n",
    "            analytics = calculate_sales_analytics(sales_only, from_date, to_date)\n",
    "            sales_analytics = pd.DataFrame({\n",
    "                'SITE': [site_code],\n",
    "                'ITEM': [item_code],\n",
    "                'MAX_DAILY_SALES': [analytics['MAX_DAILY_SALES']],\n",
    "                'MIN_DAILY_SALES': [analytics['MIN_DAILY_SALES']], \n",
    "                'AVG_DAILY_SALES': [analytics['AVG_DAILY_SALES']],\n",
    "                'SALES_TRANSACTIONS': [analytics['SALES_TRANSACTIONS']],\n",
    "                'TOTAL_SALES_QTY': [analytics['TOTAL_SALES_QTY']],\n",
    "                'SALES_PERIOD_DAYS': [analytics['SALES_PERIOD_DAYS']]\n",
    "            })\n",
    "        elif item_code:\n",
    "            # Single item, all sites\n",
    "            sales_analytics = sales_only.groupby('SITE').apply(lambda x: calculate_sales_analytics(x, from_date, to_date)).reset_index()\n",
    "            sales_analytics['ITEM'] = item_code\n",
    "        elif site_code:\n",
    "            # All items, single site\n",
    "            sales_analytics = sales_only.groupby('ITEM').apply(lambda x: calculate_sales_analytics(x, from_date, to_date)).reset_index()\n",
    "            sales_analytics['SITE'] = site_code\n",
    "        else:\n",
    "            # All items, all sites\n",
    "            sales_analytics = sales_only.groupby(['SITE', 'ITEM']).apply(lambda x: calculate_sales_analytics(x, from_date, to_date)).reset_index()\n",
    "        \n",
    "        # Merge stock and sales analytics\n",
    "        result_df = result_df.merge(sales_analytics[['SITE', 'ITEM', 'MAX_DAILY_SALES', 'MIN_DAILY_SALES', 'AVG_DAILY_SALES', 'SALES_TRANSACTIONS', 'TOTAL_SALES_QTY', 'SALES_PERIOD_DAYS']], \n",
    "                                   on=['SITE', 'ITEM'], how='left')\n",
    "        result_df['MAX_DAILY_SALES'] = result_df['MAX_DAILY_SALES'].fillna(0)\n",
    "        result_df['MIN_DAILY_SALES'] = result_df['MIN_DAILY_SALES'].fillna(0)\n",
    "        result_df['AVG_DAILY_SALES'] = result_df['AVG_DAILY_SALES'].fillna(0)\n",
    "        result_df['SALES_TRANSACTIONS'] = result_df['SALES_TRANSACTIONS'].fillna(0)\n",
    "        result_df['TOTAL_SALES_QTY'] = result_df['TOTAL_SALES_QTY'].fillna(0)\n",
    "        result_df['SALES_PERIOD_DAYS'] = result_df['SALES_PERIOD_DAYS'].fillna(0)\n",
    "    else:\n",
    "        # Add empty sales columns if sales data not available\n",
    "        result_df['MAX_DAILY_SALES'] = 0\n",
    "        result_df['MIN_DAILY_SALES'] = 0\n",
    "        result_df['AVG_DAILY_SALES'] = 0\n",
    "        result_df['SALES_TRANSACTIONS'] = 0\n",
    "        result_df['TOTAL_SALES_QTY'] = 0\n",
    "        result_df['SALES_PERIOD_DAYS'] = 0\n",
    "    \n",
    "    # Calculate stock autonomy (days of stock remaining at current sales rate)\n",
    "    result_df['STOCK_AUTONOMY_DAYS'] = result_df.apply(\n",
    "        lambda row: (row['CURRENT_STOCK'] / row['AVG_DAILY_SALES']) \n",
    "        if row['AVG_DAILY_SALES'] > 0 else float('inf'), axis=1\n",
    "    )\n",
    "    # Cap infinity values at 9999 for display purposes\n",
    "    result_df['STOCK_AUTONOMY_DAYS'] = result_df['STOCK_AUTONOMY_DAYS'].replace(float('inf'), 9999)\n",
    "    \n",
    "    # Add site names if available\n",
    "    if 'sites' in dataframes and sites_df is not None:\n",
    "        site_names = sites_df[['ID', 'SITE']].drop_duplicates()\n",
    "        site_names = site_names.rename(columns={'ID': 'SITE', 'SITE': 'SITE_NAME'})\n",
    "        result_df = result_df.merge(site_names, on='SITE', how='left')\n",
    "    \n",
    "    # Add item names and categories if available\n",
    "    if 'inventory_items' in dataframes and inventory_items_df is not None:\n",
    "        # Use DESCR1 as primary item name (item description)\n",
    "        item_info = inventory_items_df[['ITEM', 'DESCR1', 'CATEGORY']].drop_duplicates()\n",
    "        item_info['ITEM_NAME'] = item_info['DESCR1'].fillna('').astype(str)\n",
    "        \n",
    "        # Add category descriptions if available\n",
    "        if 'categories' in dataframes and categories_df is not None:\n",
    "            # Get category descriptions from DETDESCR table\n",
    "            category_descriptions = categories_df[['ID', 'DESCR']].drop_duplicates()\n",
    "            \n",
    "            # Convert ID to string to match CATEGORY column type\n",
    "            category_descriptions['ID'] = category_descriptions['ID'].astype(str)\n",
    "            category_descriptions = category_descriptions.rename(columns={'ID': 'CATEGORY', 'DESCR': 'CATEGORY_NAME'})\n",
    "            \n",
    "            # Ensure CATEGORY column is string type for merge\n",
    "            item_info['CATEGORY'] = item_info['CATEGORY'].astype(str)\n",
    "            \n",
    "            # Merge item info with category descriptions\n",
    "            item_info = item_info.merge(category_descriptions, on='CATEGORY', how='left')\n",
    "            item_info['CATEGORY_NAME'] = item_info['CATEGORY_NAME'].fillna('').astype(str)\n",
    "        else:\n",
    "            item_info['CATEGORY_NAME'] = ''\n",
    "        \n",
    "        # Merge with result_df\n",
    "        result_df = result_df.merge(\n",
    "            item_info[['ITEM', 'ITEM_NAME', 'CATEGORY', 'CATEGORY_NAME']], \n",
    "            on='ITEM', how='left'\n",
    "        )\n",
    "        \n",
    "        # Fill missing values\n",
    "        result_df['CATEGORY'] = result_df['CATEGORY'].fillna('')\n",
    "        result_df['CATEGORY_NAME'] = result_df['CATEGORY_NAME'].fillna('')\n",
    "    else:\n",
    "        # If no item data available, create empty columns\n",
    "        result_df['ITEM_NAME'] = None\n",
    "        result_df['CATEGORY'] = ''\n",
    "        result_df['CATEGORY_NAME'] = ''\n",
    "    \n",
    "    # Reorder columns to show: Site, Item, Item Description, Category, Current Stock, Total Sales, Avg Sales/Day, Max/Min Daily, Stock Autonomy, Transactions\n",
    "    final_cols = ['SITE', 'ITEM', 'ITEM_NAME', 'CATEGORY_NAME', 'CURRENT_STOCK', 'TOTAL_SALES_QTY', 'AVG_DAILY_SALES', 'MAX_DAILY_SALES', 'MIN_DAILY_SALES', 'STOCK_AUTONOMY_DAYS', 'SALES_TRANSACTIONS']\n",
    "    \n",
    "    # Keep only the columns we want in the final output\n",
    "    available_cols = [col for col in final_cols if col in result_df.columns]\n",
    "    result_df = result_df[available_cols]\n",
    "    \n",
    "    # Sort by current stock descending\n",
    "    result_df = result_df.sort_values('CURRENT_STOCK', ascending=False)\n",
    "    \n",
    "    if show_details:\n",
    "        date_range_str = \"\"\n",
    "        if from_date or to_date:\n",
    "            date_range_str = f\" (Sales from {from_date or 'start'} to {to_date or 'end'})\"\n",
    "        \n",
    "        print(f\"\\nüìä Stock & Sales Analytics{date_range_str}:\")\n",
    "        print(f\"Items analyzed: {result_df['ITEM'].nunique():,}\")\n",
    "        print(f\"Sites analyzed: {result_df['SITE'].nunique():,}\")\n",
    "        print(f\"Total current stock: {result_df['CURRENT_STOCK'].sum():,.0f}\")\n",
    "        print(f\"Average stock autonomy: {result_df[result_df['STOCK_AUTONOMY_DAYS'] < 9999]['STOCK_AUTONOMY_DAYS'].mean():.1f} days\")\n",
    "        print(f\"Items with positive stock: {(result_df['CURRENT_STOCK'] > 0).sum():,}\")\n",
    "        print(f\"Items with sales activity: {(result_df['MAX_DAILY_SALES'] > 0).sum():,}\")\n",
    "        print(f\"Items with low stock (< 30 days): {(result_df['STOCK_AUTONOMY_DAYS'] < 30).sum():,}\")\n",
    "        print(f\"Total sales transactions: {result_df['SALES_TRANSACTIONS'].sum():,.0f}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def get_stock_and_sales_summary(item_code=None, site_code=None, from_date=None, to_date=None):\n",
    "    \"\"\"Quick stock and sales summary with top results\"\"\"\n",
    "    result = calculate_stock_and_sales(item_code, site_code, from_date, to_date, show_details=True)\n",
    "    if result is not None and not result.empty:\n",
    "        print(f\"\\nüìã Top 10 Results:\")\n",
    "        display(result.head(10))\n",
    "    return result\n",
    "\n",
    "# Keep backward compatibility\n",
    "def calculate_stock(item_code=None, site_code=None, show_details=False):\n",
    "    \"\"\"Legacy function - use calculate_stock_and_sales for full functionality\"\"\"\n",
    "    return calculate_stock_and_sales(item_code, site_code, show_details=show_details)\n",
    "\n",
    "print(\"‚úÖ Enhanced stock and sales calculation functions ready!\")\n",
    "print(\"\\nUsage examples:\")\n",
    "print(\"‚Ä¢ calculate_stock_and_sales('ITEM001', 'SITE001') - Stock and all-time sales for specific item/site\")\n",
    "print(\"‚Ä¢ calculate_stock_and_sales('ITEM001', from_date='2025-01-01', to_date='2025-06-20') - Item sales in date range\")\n",
    "print(\"‚Ä¢ calculate_stock_and_sales(site_code='SITE001', from_date='2025-05-01') - All items at site from May\")\n",
    "print(\"‚Ä¢ calculate_stock_and_sales(from_date='2025-01-01', to_date='2025-03-31') - Q1 sales for all items/sites\")\n",
    "print(\"‚Ä¢ get_stock_and_sales_summary('ITEM001') - Quick overview with top 10 results\")\n",
    "print(\"\\nDate format: 'YYYY-MM-DD' (e.g., '2025-06-20')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd48db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>ITEM_NAME</th>\n",
       "      <th>CURRENT_STOCK</th>\n",
       "      <th>TOTAL_SALES_QTY</th>\n",
       "      <th>AVG_DAILY_SALES</th>\n",
       "      <th>MAX_DAILY_SALES</th>\n",
       "      <th>MIN_DAILY_SALES</th>\n",
       "      <th>STOCK_AUTONOMY_DAYS</th>\n",
       "      <th>SALES_TRANSACTIONS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14L</td>\n",
       "      <td>F001</td>\n",
       "      <td>CORNIERS 25X25X3 MM FAMECO</td>\n",
       "      <td>206.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.764706</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SITE  ITEM                   ITEM_NAME  CURRENT_STOCK  TOTAL_SALES_QTY  \\\n",
       "0  14L  F001  CORNIERS 25X25X3 MM FAMECO          206.0             17.0   \n",
       "\n",
       "   AVG_DAILY_SALES  MAX_DAILY_SALES  MIN_DAILY_SALES  STOCK_AUTONOMY_DAYS  \\\n",
       "0         1.133333              5.0              1.0           181.764706   \n",
       "\n",
       "   SALES_TRANSACTIONS  \n",
       "0                 5.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "calculate_stock_and_sales('F001', '14L', '2025-06-01', '2025-06-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection to troubleshoot webapp issue\n",
    "print(\"Testing database connection...\")\n",
    "try:\n",
    "    test_conn = pyodbc.connect(connection_string)\n",
    "    print(\"‚úÖ Connection successful\")\n",
    "    \n",
    "    # Test a simple query\n",
    "    cursor = test_conn.cursor()\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM ALLSTOCK\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"‚úÖ ALLSTOCK table has {count} rows\")\n",
    "    \n",
    "    test_conn.close()\n",
    "    print(\"‚úÖ Connection closed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e6410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "Testing groupby apply approach...\n",
      "‚úÖ Standard groupby.apply() works fine\n",
      "Result shape: (57, 2)\n",
      "Result with warnings visible completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5772\\1327024254.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  result2 = test_df.groupby('ITEM').apply(lambda x: pd.Series({'count': len(x), 'sum_qty': x['QTY'].sum()}))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check pandas version and groupby approach\n",
    "import pandas as pd\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "# Test the groupby approach used in the notebook\n",
    "test_df = sales_details_df.head(100).copy()\n",
    "test_df['QTY'] = test_df['QTY'].fillna(0)\n",
    "\n",
    "print(\"Testing groupby apply approach...\")\n",
    "try:\n",
    "    # This is the exact approach from the notebook\n",
    "    result = test_df.groupby('ITEM').apply(lambda x: pd.Series({'count': len(x), 'sum_qty': x['QTY'].sum()}))\n",
    "    print(\"‚úÖ Standard groupby.apply() works fine\")\n",
    "    print(f\"Result shape: {result.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error with groupby.apply(): {e}\")\n",
    "\n",
    "# Test with warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('default')  # Show warnings\n",
    "result2 = test_df.groupby('ITEM').apply(lambda x: pd.Series({'count': len(x), 'sum_qty': x['QTY'].sum()}))\n",
    "print(\"Result with warnings visible completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47011f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INVENTORY ITEMS (STOCK) TABLE ===\n",
      "Columns: ['ITEM', 'DESCR1', 'DESCR2', 'CATEGORY', 'SUBCAT1', 'SUBCAT2', 'WHEREIS', 'SUPPLIER', 'MASDAR', 'PACK', 'BCOSTUS', 'BCOSTLC', 'POSPRICE1', 'SALESCURRID', 'PRICEA', 'PRICEB', 'PRICEC', 'PRICED', 'PRICEE', 'PRICEF', 'BARCODE1', 'BARCODE2', 'BARCODE3', 'BARCODE4', 'PACK1', 'PACK2', 'PACK3', 'PACK4', 'PRICE1', 'PRICE2', 'PRICE3', 'PRICE4', 'MINSTOCK', 'MAXSTOCK', 'GWEIGHT', 'NWEIGHT', 'VOLUME', 'SALESDISC', 'PURCHDISC', 'SUNIT', 'VAT', 'BQTY', 'QTY', 'CDATE', 'YESNO', 'COSTUS', 'COSTLC', 'LCOST', 'STYPE', 'BUY', 'PAY', 'RBUY', 'RPAY', 'ADJUSTIN', 'ADJUSTOUT', 'PRODIN', 'PRODOUT', 'PROFORMAQTY', 'ORDERQTY', 'OQTY', 'JQTY', 'USER_', 'MIZANE', 'MIZANE1', 'MIZANE2', 'MIZANE3', 'MIZANE4', 'OFRE', 'CARTOON', 'LCOST1', 'LCOST2', 'LCOST3', 'LCOST4', 'MYPRN', 'MYCOSTUS', 'MYCOSTLC', 'POSORDER', 'OLDPRICE', 'DISC2', 'SN', 'PROFIT', 'MAXDISC', 'VATRAISON']\n",
      "CATEGORY column type: object\n",
      "CATEGORY sample values: ['5074', '5074', '5074', '5074', '5074', '5074', '5074', '5074', '5074', '5074']\n",
      "CATEGORY unique count: 81\n",
      "\n",
      "=== CATEGORIES (DETDESCR) TABLE ===\n",
      "Columns: ['ID', 'MID', 'DESCR', 'MYRATE', 'MYRATE2', 'ABREV', 'SITE', 'SID', 'SID2', 'CATEGORY']\n",
      "ID column type: int64\n",
      "ID sample values: [1, 2, 3, 4, 5, 6, 7, 5046, 9, 10]\n",
      "ID unique count: 159\n",
      "DESCR column type: object\n",
      "DESCR sample values: ['KANANGA', 'KISANGANI', 'MBANDAKA', 'NOTIFY', 'TERM']\n"
     ]
    }
   ],
   "source": [
    "# Check the structure and data types of category-related columns\n",
    "print(\"=== INVENTORY ITEMS (STOCK) TABLE ===\")\n",
    "if inventory_items_df is not None:\n",
    "    print(\"Columns:\", list(inventory_items_df.columns))\n",
    "    if 'CATEGORY' in inventory_items_df.columns:\n",
    "        print(f\"CATEGORY column type: {inventory_items_df['CATEGORY'].dtype}\")\n",
    "        print(f\"CATEGORY sample values: {inventory_items_df['CATEGORY'].head(10).tolist()}\")\n",
    "        print(f\"CATEGORY unique count: {inventory_items_df['CATEGORY'].nunique()}\")\n",
    "    else:\n",
    "        print(\"‚ùå CATEGORY column not found in inventory_items_df\")\n",
    "else:\n",
    "    print(\"‚ùå inventory_items_df is None\")\n",
    "\n",
    "print(\"\\n=== CATEGORIES (DETDESCR) TABLE ===\")\n",
    "if categories_df is not None:\n",
    "    print(\"Columns:\", list(categories_df.columns))\n",
    "    if 'ID' in categories_df.columns:\n",
    "        print(f\"ID column type: {categories_df['ID'].dtype}\")\n",
    "        print(f\"ID sample values: {categories_df['ID'].head(10).tolist()}\")\n",
    "        print(f\"ID unique count: {categories_df['ID'].nunique()}\")\n",
    "    else:\n",
    "        print(\"‚ùå ID column not found in categories_df\")\n",
    "    \n",
    "    if 'DESCR' in categories_df.columns:\n",
    "        print(f\"DESCR column type: {categories_df['DESCR'].dtype}\")\n",
    "        print(f\"DESCR sample values: {categories_df['DESCR'].head(5).tolist()}\")\n",
    "    else:\n",
    "        print(\"‚ùå DESCR column not found in categories_df\")\n",
    "else:\n",
    "    print(\"‚ùå categories_df is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae07e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVENTORY ITEMS CATEGORY column:\n",
      "Type: object\n",
      "Sample values: ['5074', '5074', '5074']\n",
      "\n",
      "CATEGORIES ID column:\n",
      "Type: int64\n",
      "Sample values: [1, 2, 3]\n",
      "\n",
      "Checking merge compatibility...\n",
      "CATEGORY null count: 5\n",
      "ID null count: 0\n"
     ]
    }
   ],
   "source": [
    "# Check data types for merge compatibility\n",
    "print(\"INVENTORY ITEMS CATEGORY column:\")\n",
    "print(f\"Type: {inventory_items_df['CATEGORY'].dtype}\")\n",
    "print(f\"Sample values: {inventory_items_df['CATEGORY'].dropna().head(3).tolist()}\")\n",
    "\n",
    "print(\"\\nCATEGORIES ID column:\")  \n",
    "print(f\"Type: {categories_df['ID'].dtype}\")\n",
    "print(f\"Sample values: {categories_df['ID'].dropna().head(3).tolist()}\")\n",
    "\n",
    "# Test merge compatibility\n",
    "print(f\"\\nChecking merge compatibility...\")\n",
    "print(f\"CATEGORY null count: {inventory_items_df['CATEGORY'].isnull().sum()}\")\n",
    "print(f\"ID null count: {categories_df['ID'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb42e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing category merge...\n",
      "‚úÖ Function ran successfully! Got 34965 rows\n",
      "Columns: ['SITE', 'ITEM', 'ITEM_NAME', 'CATEGORY_NAME', 'CURRENT_STOCK', 'TOTAL_SALES_QTY', 'AVG_DAILY_SALES', 'MAX_DAILY_SALES', 'MIN_DAILY_SALES', 'STOCK_AUTONOMY_DAYS', 'SALES_TRANSACTIONS']\n",
      "Items with category names: 34852\n",
      "Sample categories:\n",
      "       ITEM                          ITEM_NAME CATEGORY_NAME\n",
      "29596  F183           BARRE 10 MM (12M) FAMECO           BAR\n",
      "2385   F365  TOLE BAC COLOREE 3000X900X0.20 MM        T.GALV\n",
      "14951  F412               CIMENT 50KG PPC 42.5        CIMENT\n",
      "\n",
      "Top 5 results:\n",
      "      SITE    ITEM                            ITEM_NAME CATEGORY_NAME  \\\n",
      "29596  P-O    F183             BARRE 10 MM (12M) FAMECO           BAR   \n",
      "2385   A-K    F365    TOLE BAC COLOREE 3000X900X0.20 MM        T.GALV   \n",
      "14951  KIS    F412                 CIMENT 50KG PPC 42.5        CIMENT   \n",
      "29597  P-O    F184             BARRE 12 MM (12M) FAMECO           BAR   \n",
      "31760  S-T  KO6700  LAME DE SCIE 18TPI/8D 0.6X300MM CCA           JKL   \n",
      "\n",
      "       CURRENT_STOCK  TOTAL_SALES_QTY  AVG_DAILY_SALES  MAX_DAILY_SALES  \\\n",
      "29596       124507.0          10298.0       686.533333           3993.0   \n",
      "2385        106831.0              0.0         0.000000              0.0   \n",
      "14951        91690.0          24194.0      1612.933333           4901.0   \n",
      "29597        86720.0           2952.0       196.800000           1884.0   \n",
      "31760        73999.0              0.0         0.000000              0.0   \n",
      "\n",
      "       MIN_DAILY_SALES  STOCK_AUTONOMY_DAYS  SALES_TRANSACTIONS  \n",
      "29596            150.0           181.356089                17.0  \n",
      "2385               0.0          9999.000000                 0.0  \n",
      "14951            545.0            56.846739                38.0  \n",
      "29597            128.0           440.650407                 6.0  \n",
      "31760              0.0          9999.000000                 0.0  \n"
     ]
    }
   ],
   "source": [
    "# Test the category merge fix\n",
    "print(\"Testing category merge...\")\n",
    "result = calculate_stock_and_sales(from_date='2025-06-01', to_date='2025-06-15')\n",
    "\n",
    "if result is not None and not result.empty:\n",
    "    print(f\"‚úÖ Function ran successfully! Got {len(result)} rows\")\n",
    "    print(f\"Columns: {list(result.columns)}\")\n",
    "    \n",
    "    # Check if category data is populated\n",
    "    if 'CATEGORY_NAME' in result.columns:\n",
    "        non_empty_categories = result[result['CATEGORY_NAME'] != '']\n",
    "        print(f\"Items with category names: {len(non_empty_categories)}\")\n",
    "        if len(non_empty_categories) > 0:\n",
    "            print(\"Sample categories:\")\n",
    "            print(non_empty_categories[['ITEM', 'ITEM_NAME', 'CATEGORY_NAME']].head(3))\n",
    "    \n",
    "    print(f\"\\nTop 5 results:\")\n",
    "    print(result.head())\n",
    "else:\n",
    "    print(\"‚ùå Function returned None or empty result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0f3b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Category merge fixed! Function runs without error\n",
      "Sample category: 'CORNIERE'\n",
      "Result columns: ['SITE', 'ITEM', 'ITEM_NAME', 'CATEGORY_NAME', 'CURRENT_STOCK', 'TOTAL_SALES_QTY', 'AVG_DAILY_SALES', 'MAX_DAILY_SALES', 'MIN_DAILY_SALES', 'STOCK_AUTONOMY_DAYS', 'SALES_TRANSACTIONS']\n"
     ]
    }
   ],
   "source": [
    "# Simple test for category merge\n",
    "try:\n",
    "    result = calculate_stock_and_sales('F001', '14L', '2025-06-01', '2025-06-15')\n",
    "    if result is not None and not result.empty:\n",
    "        print(\"‚úÖ Category merge fixed! Function runs without error\")\n",
    "        if 'CATEGORY_NAME' in result.columns:\n",
    "            category_name = result['CATEGORY_NAME'].iloc[0] if len(result) > 0 else 'N/A'\n",
    "            print(f\"Sample category: '{category_name}'\")\n",
    "        print(f\"Result columns: {list(result.columns)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Function returned empty result\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
